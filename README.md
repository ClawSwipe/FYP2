# Quantum Convolutional Neural Networks with Hamiltonian Embedding and Ancillary Qubits

This repository presents a novel quantum machine learning framework for image classification, integrating Quantum Convolutional Neural Networks (QCNNs) with Hamiltonian embedding and ancillary qubit enhancement.

> â€œQuantum ML meets deep image understanding: This work brings together the physics-inspired Hamiltonian encoding and quantum convolution with ancilla qubits to push the limits of quantum image classification.â€

---

## ğŸ“Œ Overview

Traditional QCNNs often struggle with representing complex image data under NISQ constraints. This project addresses those limitations through:

- ğŸ§  Hamiltonian embedding: Encodes classical images into quantum states with enhanced spatial structure retention.
- â• Ancillary qubits: Increase representational capacity without significantly deepening circuits.
- ğŸ§± Quantum convolution: Localized quantum operations over qubit regions emulate classical convolutions.
- ğŸ“‰ Adaptive pooling & hybrid training: Optimized quantum state reduction and classical gradient descent.
- âš™ï¸ Noise mitigation: Resilience to noise via simulated decoherence-aware training and shallow circuit design.

---

## ğŸ§ª Datasets

Evaluated across 4 benchmark datasets:

| Dataset           | Image Size | Classes | Train | Val | Test |
|------------------|------------|---------|-------|-----|------|
| Kaggle CT Scans  | 32Ã—32      | 2       | 75    | 5   | 20   |
| SKlearn Digits   | 8Ã—8        | 8       | 1040  | 130 | 130  |
| MNIST (0â€“7)      | 32Ã—32      | 8       | 45,790| 2410| 8017 |
| FashionMNIST (0â€“7)| 32Ã—32     | 8       | 45,600| 2400| 8000 |

---

## ğŸ—ï¸ Architecture

The model integrates the following modules:

1. Hamiltonian Embedding:
   - Constructs Hermitian matrices from images: 
     HM = (M + Máµ€)/2
   - Applies unitary evolution: W(t;M) = e^{-iHM t/2}

2. Ancillary Qubit Enhancement:
   - Introduces |0âŸ© ancilla qubits
   - Interacts with data qubits using controlled unitaries to expand Hilbert space

3. Quantum Convolution:
   - Applies Uj(Î¸) gates over localized qubit patches
   - Emulates classical convolution using quantum operations

4. Adaptive Pooling:
   - Measurement-based pooling reduces qubit usage while preserving key features

5. Hybrid Optimization:
   - Combines quantum evolution with classical training (cross-entropy loss, natural gradient descent, layer-wise pretraining)

---

## ğŸ”¬ Experimental Results

| Model                   | Kaggle CT | SKlearn | MNIST | Fashion |
|------------------------|-----------|---------|--------|---------|
| Classical CNN          | 85.0%     | 97.7%   | 98.9%  | 89.3%   |
| Standard QCNN          | 76.5%     | 92.3%   | 94.1%  | 82.5%   |
| QNN (no conv, no ancilla)| 72.0%    | 89.2%   | 91.8%  | 78.4%   |
| Hamiltonian-QNN        | 80.5%     | 94.6%   | 95.7%  | 84.1%   |
| Ours (Full Model)      | 82.5%     | 96.2%   | 97.2%  | 86.7%   |

âœ… Our model consistently outperforms baseline quantum models while approaching classical CNN performance, especially on smaller datasets.

---

## ğŸ”§ Implementation Details

- Quantum Libraries: Qiskit, PennyLane
- Classical Backend: PyTorch
- Hardware: IBM-Q Eagle 127-qubit processor (for smaller instances)
- Simulation: Device-calibrated noise models
- Batch Sizes: 16â€“32 samples
- Optimizer: Quantum Natural Gradient Descent
- Training: 100 epochs with early stopping

---

## ğŸ“ˆ Ablation Study

Key findings:

| Removed Component        | Accuracy Drop |
|-------------------------|----------------|
| No Convolution          | â†“ 5.7%         |
| No Hamiltonian Embedding| â†“ 3.1%         |
| No Ancillary Qubits     | â†“ 1.4%         |
| No Layer-wise Pretrain  | â†“ 0.8%         |

ğŸ§© The convolutional structure and Hamiltonian embedding contribute most to performance gains.

---

## ğŸ›¡ï¸ Noise Robustness

- Model shows only 5.2% degradation at 10â»Â³ gate error rate (typical for NISQ)
- Outperforms other quantum models under same conditions
- Includes error detection circuits and noise-aware training

---

## ğŸ“š Citations

If you use this work, please cite:

```bibtex
@article{talha2025quantumcnn,
  title={Quantum Convolutional Architectures for Image Classification: A Hamiltonian-Embedded Approach with Ancillary Qubits},
  author={Muhammad Talha Shaikh, Muhammad Hamza, Syed Bilal Ali, Sumaiyah Zahid, Muhammad Rafi},
  journal={FYP II Report, FAST-NUCES},
  year={2025}
}
```
##Structure
quantum_cnn_project/
â”œâ”€â”€ ct-med-img/                # Preprocessed datasets
â”œâ”€â”€ sklearn-digits-dataset/            # Qiskit & PennyLane circuit files
â”œâ”€â”€ mnist/              # Architecture & training scripts
â”œâ”€â”€ fashion-mnist/             # Experimental outputs & plots
â”œâ”€â”€ README.md            # Project documentation


This project was conducted as a Final Year Project at FAST-NUCES Karachi.


